{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><B>Atrribute Extractor</B></H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions from libraries\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableLambda\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import yaml\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: One Attribute at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettiing api_key from env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_yaml(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking all file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names\n",
    "# Provide the product_description and attributes_description file in csv format\n",
    "model_details = 'model_details.yaml'\n",
    "product_description_file_name = 'source_files/p_description.csv'\n",
    "atrributes_description_file_name = 'source_files/a_description.csv'\n",
    "example_file_name = 'sku example.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable example sementic similarity option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Y/N\n",
    "Run_semantic_similarity_option = \"N\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create an OpenAI api client by taking model settings from a yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_settings(file_name,api_key):\n",
    "\n",
    "    # Load YAML data from a file\n",
    "    data = import_yaml(file_name)\n",
    "\n",
    "    # Print the loaded data\n",
    "    # Setting up OpenAI client\n",
    "\n",
    "    model = ChatOpenAI(model=data['model_name'],\n",
    "                    api_key=api_key)\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to import data from product_description and attributes_description csv files and combining them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importing\n",
    "def data_importing(product_description_file_name, atrributes_description_file_name):\n",
    "    import pandas as pd\n",
    "    product_description_df = pd.read_csv(product_description_file_name)\n",
    "    attribute_description_df = pd.read_csv(atrributes_description_file_name)\n",
    "    return(pd.merge(product_description_df, attribute_description_df, how='cross'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to convert the combined dataframe into list of dictionaries which would be model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning \n",
    "def data_cleaning(imported_data):\n",
    "    list_of_dictionaries = []\n",
    "    for i in range(imported_data.shape[0]):\n",
    "            list_of_dictionaries.append({'attribute_name':imported_data['Atrribute Name'][i],\n",
    "                                            'attribute_description':imported_data['Attribute Description'][i],\n",
    "                                            'attribute_example':imported_data['Example'][i],\n",
    "                                            'other_information':imported_data['Other Information'][i],\n",
    "                                            'product_description':imported_data['SKU Description'][i] + \" \" + imported_data['SKU Description'][i]})\n",
    "    return(list_of_dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create prompt\n",
    "prompt_to_extract_attrbutes = ChatPromptTemplate.from_messages([\n",
    "    ('system',\"You are a data entry operator, only provide one word answers from the product description provided. If you don't find the answer in product description return Not available\"),\n",
    "    ('human','Extract the following attribute: Attribute name:{attribute_name}, Attribute description:{attribute_description}, Attribute example:{attribute_example} and Other information:{other_information} from Product description:{product_description}')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a runnable chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating chains\n",
    "def extracting_attributes_using_open_ai(prompt,model,data):\n",
    "    chain_attribute_extractor = prompt | model | StrOutputParser()\n",
    "    return(chain_attribute_extractor.batch(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove duplicate values from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicates from the value column\n",
    "\n",
    "def remove_duplicate_values(df, product_column, value_column):\n",
    "    df[value_column] = df.groupby(product_column)[value_column].transform(\n",
    "        lambda group: group.where(~group.duplicated(), 'Not available')\n",
    "    )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to format the output from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output formating\n",
    "def output_formating(data,output):\n",
    "    data['Value'] = output\n",
    "    data = remove_duplicate_values(data,'SKU Name','Value')\n",
    "    data = data[['SKU Name', 'SKU Description', 'Atrribute Name','Value']]\n",
    "    data = data.pivot(index=['SKU Name','SKU Description'], columns='Atrribute Name', values='Value').reset_index()\n",
    "    data.columns.name = None\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example selector by semantics\n",
    "# function to create an example dictionary\n",
    "import pandas as pd\n",
    "def Add_Examples_for_model_col(data,example_file_name):\n",
    "    data_for_example = pd.read_csv(example_file_name)\n",
    "    data_for_example = data_for_example.melt(id_vars=['SKU Name','SKU Description'],var_name='Atrribute Name',value_name='Value')\n",
    "    data_for_example['Examples_for_model'] = data_for_example.apply(lambda data_for_example: {'Product_description':data_for_example['SKU Description'],'Attribute_name':data_for_example['Atrribute Name'],'Value':data_for_example['Value']}, axis = 1)\n",
    "    data_for_example = data_for_example.groupby('Atrribute Name')['Examples_for_model'].agg(list).reset_index()\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name)\n",
    "    data = pd.merge(data,data_for_example,on='Atrribute Name')\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_extractor(Attribute_name,Examples,api_key,number_of_examples):\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"Product_description\",\"Attribute_name\", \"Value\"],\n",
    "        template=\"Product_description: {Product_description} Attribute_name: {Attribute_name} Value:{Value}\",\n",
    "    )\n",
    "    examples = Examples\n",
    "    example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "        # The list of examples available to select from.\n",
    "        examples,\n",
    "        # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "        OpenAIEmbeddings(api_key=api_key),\n",
    "        # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "        FAISS,\n",
    "        # The number of examples to produce.\n",
    "        k=number_of_examples,\n",
    "    )\n",
    "    similar_prompt = FewShotPromptTemplate(\n",
    "        # We provide an ExampleSelector instead of examples.\n",
    "        example_selector=example_selector,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=\"\",\n",
    "        suffix=\"\",\n",
    "        input_variables=[\"Attribute_name\"],\n",
    "    )\n",
    "    # Input is a feeling, so should select the happy/sad example\n",
    "    final_examples = similar_prompt.format(Attribute_name = Attribute_name)\n",
    "    return(final_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_example(data,Attribute_name_column_name,All_examples_column_name,Relevent_example_column_name,api_key,number_of_examples):\n",
    "    semantic_similar_exaples = []\n",
    "    for i in range(data.shape[0]):\n",
    "        semantic_similar_exaples.append(example_extractor(data[Attribute_name_column_name][i],data[All_examples_column_name][i],api_key,number_of_examples))\n",
    "    data[Relevent_example_column_name] = semantic_similar_exaples\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a semantic similarity example pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a pipeline\n",
    "def example_semantic_similary_pipeline(product_description_file_name,atrributes_description_file_name,example_file_name,api_key,number_of_examples,Atrribute_name,Examples_for_model,Examples_selected_by_semantic_similarity):\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name)\n",
    "    data = Add_Examples_for_model_col(data,example_file_name)\n",
    "    data = similar_example(data,Atrribute_name,Examples_for_model,Examples_selected_by_semantic_similarity,api_key,number_of_examples)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pipeline which takes file names, api_key and prompt as input to provide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline which takes both file names, model and prompt to produce the output\n",
    "def pipeline(product_description_file_name, atrributes_description_file_name,model_file_name,api_key,prompt,Run_semantic_similarity_option,example_file_name,number_of_examples,Atrribute_Name,Examples_for_model,Example):\n",
    "    model = model_settings(model_file_name,api_key) # Importing llm\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name) #Data importing\n",
    "    if Run_semantic_similarity_option == 'Y': data = example_semantic_similary_pipeline(product_description_file_name,atrributes_description_file_name,example_file_name,api_key,number_of_examples,Atrribute_Name,Examples_for_model,Example) #Example semantic similarity\n",
    "    data_cleaned = data_cleaning(data) #Formating the input data\n",
    "    output = extracting_attributes_using_open_ai(prompt,model,data_cleaned) #Running the llm for answers\n",
    "    output_formated = output_formating(data,output) #Fromating the output from llm\n",
    "    return(output_formated) #Output of the function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = pipeline(product_description_file_name,atrributes_description_file_name,model_details,api_key,prompt_to_extract_attrbutes,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU Name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Flavour</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700144801 - TIP TOP NYONYA KUIH BANGKIT 60G</td>\n",
       "      <td>TIP TOP</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0750073001 - TONG GARDEN SHRIMP COATED PEANUT ...</td>\n",
       "      <td>Tong Garden</td>\n",
       "      <td>Shrimp</td>\n",
       "      <td>Peanut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0750073101 - TONG GARDEN CHICKEN COATED PEANUT...</td>\n",
       "      <td>Tong Garden</td>\n",
       "      <td>Chicken</td>\n",
       "      <td>Peanut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0750073201 - TONG GARDEN BBQ COATED PEANUT 160G</td>\n",
       "      <td>TONG</td>\n",
       "      <td>BBQ</td>\n",
       "      <td>Peanut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0790080001 - OTTOGI DRIED SEAWEED 50G</td>\n",
       "      <td>Ottogi</td>\n",
       "      <td>Seaweed</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>3230000301 - KUIH MASIN/MASIN WANGI 4S</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>3230000901 - ROTI AYAM &amp; IKAN 200G</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>3230001101 - KACANG TUMBUK 6S</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Kacang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>3230001201 - GULA TARIK 6S</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3230001601 - KACANG PARANG 150G</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Kacang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               SKU Name  ...           Type\n",
       "0          0700144801 - TIP TOP NYONYA KUIH BANGKIT 60G  ...  Not available\n",
       "1     0750073001 - TONG GARDEN SHRIMP COATED PEANUT ...  ...         Peanut\n",
       "2     0750073101 - TONG GARDEN CHICKEN COATED PEANUT...  ...         Peanut\n",
       "3       0750073201 - TONG GARDEN BBQ COATED PEANUT 160G  ...         Peanut\n",
       "4                 0790080001 - OTTOGI DRIED SEAWEED 50G  ...  Not available\n",
       "...                                                 ...  ...            ...\n",
       "1495             3230000301 - KUIH MASIN/MASIN WANGI 4S  ...  Not available\n",
       "1496                 3230000901 - ROTI AYAM & IKAN 200G  ...  Not available\n",
       "1497                      3230001101 - KACANG TUMBUK 6S  ...         Kacang\n",
       "1498                         3230001201 - GULA TARIK 6S  ...  Not available\n",
       "1499                    3230001601 - KACANG PARANG 150G  ...         Kacang\n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1.drop(columns=['SKU Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: One product at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_2(data):\n",
    "    list_of_dictionaries = []\n",
    "    for product in data['SKU Name'].unique():\n",
    "        list_of_dictionaries.append({'attribute_name':list(data[data['SKU Name'] == product]['Atrribute Name']),\n",
    "                                    'attribute_description':list(data[data['SKU Name'] == product]['Attribute Description']),\n",
    "                                    'attribute_example':list(data[data['SKU Name'] == product]['Example']),\n",
    "                                    'other_information':list(data[data['SKU Name'] == product]['Other Information']),\n",
    "                                    'product_description':list(data[data['SKU Name'] == product]['SKU Description'])})\n",
    "    return(list_of_dictionaries)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create prompt\n",
    "prompt_to_extract_attrbutes_2 = ChatPromptTemplate.from_messages([\n",
    "    ('system',\"You are a data entry operator, only provide one word answers from the product description provided. If you don't find the answer in product description return Not available and make sure do not provide same answers for two diffrent attributes in case of duplicates keep the first one and make all other Not available\"),\n",
    "    ('human','Extract the following list of attribute: Attribute name:{attribute_name}, Attribute description:{attribute_description}, Attribute example:{attribute_example} and Other information:{other_information} from Product description:{product_description}')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_formating_2(data,output):\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name)\n",
    "    data = data[['SKU Name','SKU Description']].drop_duplicates(subset='SKU Name')\n",
    "    data = data.reset_index(drop=True)\n",
    "    #dict_list = [dict(item.split(\": \") for item in entry.split(\"\\n\")) for entry in output]\n",
    "    dict_list =[dict(item.split(\": \", 1) for item in entry.split(\"\\n\") if \": \" in item) for entry in output]\n",
    "    data = pd.concat([data,pd.DataFrame(dict_list)],axis=1)\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline which takes both file names, model and prompt to produce the output\n",
    "def pipeline_2(product_description_file_name, atrributes_description_file_name,model_file_name,api_key,prompt,Run_semantic_similarity_option,example_file_name,number_of_examples,Atrribute_Name,Examples_for_model,Example):\n",
    "    model = model_settings(model_file_name,api_key)\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name) #Data importing\n",
    "    if Run_semantic_similarity_option == 'Y': data = example_semantic_similary_pipeline(product_description_file_name,atrributes_description_file_name,example_file_name,api_key,number_of_examples,Atrribute_Name,Examples_for_model,Example) #Example semantic similarity\n",
    "    data_cleaned = data_cleaning_2(data) #Formating the input data\n",
    "    output = extracting_attributes_using_open_ai(prompt,model,data_cleaned) #Running the llm for answers\n",
    "    output_formated = output_formating_2(data,output) #Fromating the output from llm\n",
    "    return(output_formated) #Output of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = pipeline_2(product_description_file_name, atrributes_description_file_name,model_details,api_key,prompt_to_extract_attrbutes_2,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Each Attribute in diffrent parallel chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning_3(data):\n",
    "    test = []\n",
    "    for products in data['SKU Description'].unique():\n",
    "        test.append({'product_description':products})\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prompt and their response\n",
    "def extracting_attributes_using_open_ai_3(model,data,data_cleaned):\n",
    "    runnable_parallel_dict = {}\n",
    "    attribute_name_list = []\n",
    "    for attribute_name in data['Atrribute Name'].unique():\n",
    "        attribute_name_list.append(attribute_name)\n",
    "        human_prompt = 'Extract the following attribute: Attribute name:'+attribute_name+', Attribute description:'+data[data['Atrribute Name']==attribute_name]['Attribute Description'].unique()+', Attribute example:'+data[data['Atrribute Name']==attribute_name]['Example'].unique()+' and Other information:'+data[data['Atrribute Name']==attribute_name]['Other Information'].unique()+' from Product description:{product_description}'\n",
    "        prompt_atrribute_extractor = (ChatPromptTemplate.from_messages([\n",
    "            ('system',\"You are a data entry operator, only provide one word answers from the product description provided. If you don't find the answer in product description return Not available and make sure do not provide same answers for two diffrent attributes in case of duplicates keep the first one and make all other Not available\"),\n",
    "            ('human',human_prompt[0])\n",
    "        ]))\n",
    "        chain = prompt_atrribute_extractor | model | StrOutputParser()\n",
    "        runnable_parallel_dict = runnable_parallel_dict | {attribute_name:chain}\n",
    "    \n",
    "    make_list_chain = RunnableLambda(lambda x: list(x['branches'].values()))\n",
    "    prompt_remove_duplicates = ChatPromptTemplate.from_messages([\n",
    "        ('human',\"ensure length of input and output list should be same\"),\n",
    "        ('human',\"Except 'Not avialable' replace other duplicates in:  {list_of_output} with 'Not available'\"),\n",
    "        ('human',\"Only return the list in the output\")\n",
    "    ])\n",
    "\n",
    "    chain_remove_duplicates = prompt_remove_duplicates | model | StrOutputParser()\n",
    "    #chain = RunnableParallel(branches = runnable_parallel_dict) | make_list_chain | chain_remove_duplicates\n",
    "    chain = RunnableParallel(branches = runnable_parallel_dict) | make_list_chain\n",
    "    output = chain.batch(data_cleaned)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output formating\n",
    "def output_formating_3(data,output):\n",
    "    #data['Value'] = [item for sublist in output for item in ast.literal_eval(sublist)]\n",
    "    data['Value'] = [item for sublist in output for item in sublist]\n",
    "    #data['Value'] = [dict(item.split(\": \", 1) for item in entry.split(\"\\n\") if \": \" in item) for entry in output]\n",
    "    data = remove_duplicate_values(data,'SKU Name','Value')\n",
    "    data = data[['SKU Name', 'SKU Description', 'Atrribute Name','Value']]\n",
    "    data = data.pivot(index=['SKU Name','SKU Description'], columns='Atrribute Name', values='Value').reset_index()\n",
    "    data.columns.name = None\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline which takes both file names, model and prompt to produce the output\n",
    "def pipeline_3(product_description_file_name, atrributes_description_file_name,model_file_name,api_key,Run_semantic_similarity_option,example_file_name,number_of_examples,Atrribute_Name,Examples_for_model,Example):\n",
    "    model = model_settings(model_file_name,api_key)\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name) #Data importing\n",
    "    if Run_semantic_similarity_option == 'Y': data = example_semantic_similary_pipeline(product_description_file_name,atrributes_description_file_name,example_file_name,api_key,number_of_examples,Atrribute_Name,Examples_for_model,Example) #Example semantic similarity\n",
    "    data_cleaned = data_cleaning_3(data) #Formating the input data\n",
    "    output = extracting_attributes_using_open_ai_3(model,data,data_cleaned) #Running the llm for answers\n",
    "    output_formated = output_formating_3(data,output) #Fromating the output from llm\n",
    "    return(output_formated) #Output of the functionoutput_formating_3(data,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_3 = pipeline_3(product_description_file_name, atrributes_description_file_name,model_details,api_key,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4: Simple sequential chain for all attribute connected parallely for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prompt\n",
    "def extracting_attributes_using_open_ai_4(model,data,data_cleaned):\n",
    "    runnable_parallel_dict = {}\n",
    "    attribute_name_list = []\n",
    "    for product_description in data['SKU Description'].unique():\n",
    "        product_name = str(data[data['SKU Description'] == product_description]['SKU Name'].unique())\n",
    "        chain_combine = RunnableLambda(lambda x:x)\n",
    "        for attribute_name in data['Atrribute Name'].unique():\n",
    "            attribute_name_list.append(attribute_name)\n",
    "            human_prompt = 'Extract a one word respose for the following attribute: Attribute name:'+attribute_name+', Attribute description: '+data[data['Atrribute Name']==attribute_name]['Attribute Description'].unique()+', Attribute example: '+data[data['Atrribute Name']==attribute_name]['Example'].unique()+' and Other information: '+data[data['Atrribute Name']==attribute_name]['Other Information'].unique()+' from Product description: '+ product_description\n",
    "            prompt_atrribute_extractor = ChatPromptTemplate.from_messages([\n",
    "                ('system',\"You are a data entry operator, append your answer in the folliwng list: {list_of_output} and only provide this list as output\"),\n",
    "                ('human',human_prompt[0]),\n",
    "                ('human',\"if the answer is already part of :{list_of_output}, change your answer to 'Not available'\"),\n",
    "                ('human',\"In case the attribute is not present in the product description append 'Not available' to the list:{list_of_output}. In all other cases make your asnwer 'Not available'\")\n",
    "            ])\n",
    "            chain = prompt_atrribute_extractor | model | StrOutputParser()\n",
    "            chain_combine = chain_combine | chain\n",
    "        runnable_parallel_dict = runnable_parallel_dict | {product_name:chain_combine}\n",
    "\n",
    "    chain_final = RunnableParallel(branches = runnable_parallel_dict)\n",
    "    #chain = RunnableParallel(branches = runnable_parallel_dict) | RunnableLambda(lambda x: combination_chains(x[\"branches\"]))\n",
    "    output = chain_final.invoke(data_cleaned)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output formating\n",
    "def output_formating_4(data,output):\n",
    "    import ast\n",
    "    data['Value'] = [item for sublist in list(output['branches'].values()) for item in ast.literal_eval(sublist)]\n",
    "    #data = remove_duplicate_values(data,'SKU Name','Value')\n",
    "    data = data[['SKU Name', 'SKU Description', 'Atrribute Name','Value']]\n",
    "    data = data.pivot(index=['SKU Name','SKU Description'], columns='Atrribute Name', values='Value').reset_index()\n",
    "    data.columns.name = None\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline which takes both file names, model and prompt to produce the output\n",
    "def pipeline_4(product_description_file_name, atrributes_description_file_name,model_file_name,api_key,Run_semantic_similarity_option,example_file_name,number_of_examples,Atrribute_Name,Examples_for_model,Example):\n",
    "    output = [] # Creating an outputlist\n",
    "    model = model_settings(model_file_name,api_key)\n",
    "    data = data_importing(product_description_file_name,atrributes_description_file_name) #Data importing\n",
    "    if Run_semantic_similarity_option == 'Y': data = example_semantic_similary_pipeline(product_description_file_name,atrributes_description_file_name,example_file_name,api_key,number_of_examples,Atrribute_Name,Examples_for_model,Example) #Example semantic similarity\n",
    "    data_cleaned = [] #Formating the input data\n",
    "    output = extracting_attributes_using_open_ai_4(model,data,data_cleaned) #Running the llm for answers\n",
    "    output_formated = output_formating_4(data,output) #Fromating the output from llm\n",
    "    return(output_formated) #Output of the functionoutput_formating_3(data,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_4 = pipeline_4(product_description_file_name, atrributes_description_file_name,model_details,api_key,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub-department</th>\n",
       "      <th>Category</th>\n",
       "      <th>Type</th>\n",
       "      <th>Flavour</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Pack size</th>\n",
       "      <th>Price tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250 - SNACKS</td>\n",
       "      <td>0473 - CORN SNACKS</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0821614601 - KOREAN COLOR CURRY POPCORN 80G</td>\n",
       "      <td>Small</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250 - SNACKS</td>\n",
       "      <td>0477 - NUTS</td>\n",
       "      <td>Seeds</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Tong Garden</td>\n",
       "      <td>0821620101 - TONG GARDEN SUNFLOWER SEEDS NO SH...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250 - SNACKS</td>\n",
       "      <td>0477 - NUTS</td>\n",
       "      <td>Seeds</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Unbranded</td>\n",
       "      <td>0820277101 - WHITE PUMPKIN SEED 500G</td>\n",
       "      <td>Large</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250 - SNACKS</td>\n",
       "      <td>0477 - NUTS</td>\n",
       "      <td>Mixed nuts</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Taisun</td>\n",
       "      <td>0821069201 - TAISUN TREATZ VEGGIE STICKS 250G</td>\n",
       "      <td>Large</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250 - SNACKS</td>\n",
       "      <td>0477 - NUTS</td>\n",
       "      <td>Kacang</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Alwi</td>\n",
       "      <td>0820088501 - ALWI KACANG CORNFLAKES 40G</td>\n",
       "      <td>Small</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sub-department            Category  ... Pack size Price tier\n",
       "0   250 - SNACKS  0473 - CORN SNACKS  ...     Small     Medium\n",
       "1   250 - SNACKS         0477 - NUTS  ...    Medium        Low\n",
       "2   250 - SNACKS         0477 - NUTS  ...     Large        Low\n",
       "3   250 - SNACKS         0477 - NUTS  ...     Large     Medium\n",
       "4   250 - SNACKS         0477 - NUTS  ...     Small        Low\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_data = pd.read_excel('nuts.xlsx')\n",
    "source_file_data ['Type'] = source_file_data['Type'].fillna('Not available')\n",
    "source_file_data ['Flavour'] = source_file_data['Flavour'].fillna('Not available')\n",
    "source_file_data ['Brand'] = source_file_data['Brand'].fillna('Not available')\n",
    "source_file_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(source_file_data,output):\n",
    "    source_file_data = source_file_data.rename(columns={'Type': 'Type_source', 'Flavour': 'Flavour_source', 'Brand': 'Brand_source'})\n",
    "    merged_data = pd.merge(source_file_data, output, left_on='Description', right_on='SKU Name', how='inner')\n",
    "    type_matches = merged_data['Type'] == merged_data['Type_source']\n",
    "    brand_matches = merged_data['Brand'] == merged_data['Brand_source']\n",
    "    flavour_matches = merged_data['Flavour'] == merged_data['Flavour_source']\n",
    "\n",
    "    # Step 2: Calculate the number of matches\n",
    "    total_matches = (type_matches.sum() + brand_matches.sum() + flavour_matches.sum())  # Total matching rows for columns\n",
    "    total_comparisons = len(merged_data) * 3  # Total comparisons (3 per row)\n",
    "\n",
    "    # Step 3: Calculate accuracy\n",
    "    accuracy = (total_matches / total_comparisons) * 100\n",
    "    accuracy_type = (type_matches.sum() / len(merged_data)) * 100\n",
    "    accuracy_brand = (brand_matches.sum() / len(merged_data)) * 100\n",
    "    accuracy_flavour = (flavour_matches.sum() / len(merged_data)) * 100\n",
    "\n",
    "    print(f\"Total Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Accuracy for Type column: {accuracy_type:.2f}%\")\n",
    "    print(f\"Accuracy for Brand column: {accuracy_brand:.2f}%\")\n",
    "    print(f\"Accuracy Flavour column: {accuracy_flavour:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach 1:\n",
      "\n",
      "Total Accuracy: 47.36%\n",
      "Accuracy for Type column: 78.67%\n",
      "Accuracy for Brand column: 25.20%\n",
      "Accuracy Flavour column: 38.20%\n",
      "None\n",
      "Approach 2: \n",
      "\n",
      "Total Accuracy: 30.91%\n",
      "Accuracy for Type column: 50.73%\n",
      "Accuracy for Brand column: 13.87%\n",
      "Accuracy Flavour column: 28.13%\n",
      "None\n",
      "Approach 3: \n",
      "\n",
      "Total Accuracy: 57.31%\n",
      "Accuracy for Type column: 80.60%\n",
      "Accuracy for Brand column: 45.00%\n",
      "Accuracy Flavour column: 46.33%\n",
      "None\n",
      "Approach 4: \n",
      "\n",
      "Total Accuracy: 74.33%\n",
      "Accuracy for Type column: 77.73%\n",
      "Accuracy for Brand column: 66.07%\n",
      "Accuracy Flavour column: 79.20%\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Approach 1:\\n\")\n",
    "print(accuracy(source_file_data,output_1))\n",
    "print(\"Approach 2: \\n\")\n",
    "print(accuracy(source_file_data,output_2))\n",
    "print(\"Approach 3: \\n\")\n",
    "print(accuracy(source_file_data,output_3))\n",
    "print(\"Approach 4: \\n\")\n",
    "print(accuracy(source_file_data,output_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_importing(product_description_file_name,atrributes_description_file_name)\n",
    "# model = model_settings(model_details,api_key)\n",
    "# data_cleaned = []\n",
    "# output = extracting_attributes_using_open_ai_4(model,data,data_cleaned)\n",
    "# import ast\n",
    "# flattened_list = [item for sublist in list(output['branches'].values()) for item in ast.literal_eval(sublist)]\n",
    "# len(flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = pipeline_2(product_description_file_name, atrributes_description_file_name,model_details,api_key,prompt_to_extract_attrbutes_2)\n",
    "#output.to_csv('sku example.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress testing the pipeplines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     pipeline(product_description_file_name,atrributes_description_file_name,model_details,api_key,prompt_to_extract_attrbutes,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')\n",
    "#     print(\"Completed: \",i,\"%\",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     pipeline_2(product_description_file_name, atrributes_description_file_name,model_details,api_key,prompt_to_extract_attrbutes_2,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')\n",
    "#     print(\"Completed: \",i,\"%\",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     pipeline_3(product_description_file_name, atrributes_description_file_name,model_details,api_key,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')\n",
    "#     print(\"Completed: \",i,\"%\",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     pipeline_4(product_description_file_name, atrributes_description_file_name,model_details,api_key,Run_semantic_similarity_option,example_file_name,2,'Atrribute Name','Examples_for_model','Example')\n",
    "#     print(\"Completed: \",i,\"%\",end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
